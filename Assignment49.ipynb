{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94e4fb7-a4a7-45cd-9849-9bf22bc2e2d9",
   "metadata": {},
   "source": [
    "## Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8699e1-3244-417b-b30b-19275044b4cc",
   "metadata": {},
   "source": [
    "### Ridge regression is a model tuning method that is used to analyse any data that suffers from multicollinearity. This method performs L2 regularization. When the issue of multicollinearity occurs, least-squares are unbiased, and variances are large\n",
    "### Ridge regression is a term used to refer to a linear regression model whose coefficients are estimated not by ordinary least squares (OLS), but by an estimator, called ridge estimator, that, albeit biased, has lower variance than the OLS estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f62fb0-9aa0-48b3-916f-68b5b071c05c",
   "metadata": {},
   "source": [
    "## Q2. What are the assumptions of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a54c6-de7f-400d-9eeb-469cfe07e98b",
   "metadata": {},
   "source": [
    "### The assumptions of ridge regression are the same as that of linear regression: linearity, constant variance, and independence. However, as ridge regression does not provide confidence limits, the distribution of errors to be normal need not be assumed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b68911-8378-44ba-85d5-d2cd91ad0e38",
   "metadata": {},
   "source": [
    "## Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de1158e-f8bc-483c-87a2-48e82a3a72d9",
   "metadata": {},
   "source": [
    "## Cross-validation is a way to tune the hyperparameters using only the training data. There are different variations of cross-validation, but the most common one is 10-Fold Cross-Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add4ef98-53b6-4163-8524-27c183c49cc5",
   "metadata": {},
   "source": [
    "## Q4. Can Ridge Regression be used for feature selection? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65179d-6211-4751-91e4-5505be42a223",
   "metadata": {},
   "source": [
    "### You could see ridge regression as doing the feature 'selection' in a nuanced way by reducing the size of the coefficients instead of setting them equal to zero.You could elliminate the features with the smaller coefficients*, but it is a bit crude method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5017225a-c4f8-43cc-8cd9-35b92e66b47c",
   "metadata": {},
   "source": [
    "## Q5. How does the Ridge Regression model perform in the presence of multicollinearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a9faa-f81b-4afe-9f8d-ceea4f02c56e",
   "metadata": {},
   "source": [
    "### Ridge Regression is a technique for analyzing multiple regression data that suffer from multicollinearity. When multicollinearity occurs, least squares estimates are unbiased, but their variances are large so they may be far from the true value. By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors. It is hoped that the net effect will  to give estimates that are more reliable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f839a5ed-78e4-43cb-a1cb-f2a3ce2f2499",
   "metadata": {},
   "source": [
    "## Q6. Can Ridge Regression handle both categorical and continuous independent variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1049083d-dd58-449b-ba1f-c68683d9d02d",
   "metadata": {},
   "source": [
    "### Ridge regression is used for regression purpose only as it needs the dependent variable to be continuous. So for your analysis Ridge regression can't be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb9d61-8d52-4ebb-a399-1a83bf1a8c3f",
   "metadata": {},
   "source": [
    "## Q7. How do you interpret the coefficients of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f5e73e-92d2-4518-9ff1-db1ae0181609",
   "metadata": {},
   "source": [
    "### The ridge coefficients are a reduced factor of the simple linear regression coefficients and thus never attain zero values but very small values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2c1df8-b5f6-46f0-be1c-420b8541e8a7",
   "metadata": {},
   "source": [
    "## Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc690916-fdc5-4b56-ac14-ae92b3f04f00",
   "metadata": {},
   "source": [
    "### Ridge regression has the advantage of having an easy to compute analytic solution, where the coefficients associated with the least relevant predictors are shrunk towards zero, but never reaching exactly zero. Therefore, it cannot be used for selecting predictors, unless some truncation scheme is employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38503c20-28e9-421d-99e4-98f2b7a9b0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
